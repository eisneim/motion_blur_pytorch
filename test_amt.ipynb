{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e475c6-c27f-46db-97c1-19a189a52325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from amt.AMT_L import Model\n",
    "\n",
    "amtl = Model(corr_radius=3,\n",
    "    corr_lvls=4,\n",
    "    num_flows=5)\n",
    "ckpt = torch.load(\"/Users/teli/www/ml/frame_interpolation/AMT/_pretrained/amt-l.pth\", map_location=\"cpu\")\n",
    "amtl.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86f9efa4-9158-4b3f-aa90-4a8ca9c607d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c5ae33-abd2-4e30-af46-436111f4627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from amt.utils.utils import (\n",
    "    read, write,\n",
    "    img2tensor, tensor2img,\n",
    "    check_dim_and_resize, InputPadder\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------- Initialization ----------------------- \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "img0_path = \"/Users/teli/www/pyProject/motion_blur_pytorch/dist/images/amt-34-0.jpg\"\n",
    "img1_path = \"/Users/teli/www/pyProject/motion_blur_pytorch/dist/images/amt-34-1.jpg\"\n",
    "out_path = \"/Users/teli/www/pyProject/motion_blur_pytorch/dist/output\"\n",
    "if osp.exists(out_path) is False:\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "model = amtl.to(device)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------  Load input frames ----------------------- \n",
    "img0 = read(img0_path)\n",
    "img1 = read(img1_path)\n",
    "img0_t = img2tensor(img0).to(device)\n",
    "img1_t = img2tensor(img1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40b3228a-ab46-4e6d-b1bf-b5fdd2e9d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpoate(model, img0, img1, frame_ratio=24, iters=4): # 2~7\n",
    "    inputs = [img0_t, img1_t]\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        anchor_resolution = 1024 * 512\n",
    "        anchor_memory = 1500 * 1024**2\n",
    "        anchor_memory_bias = 2500 * 1024**2\n",
    "        vram_avail = torch.cuda.get_device_properties(device).total_memory\n",
    "    else:\n",
    "        # Do not resize in cpu mode\n",
    "        anchor_resolution = 8192*8192\n",
    "        anchor_memory = 1\n",
    "        anchor_memory_bias = 0\n",
    "        vram_avail = 1\n",
    "    embt = torch.tensor(1/2).float().view(1, 1, 1, 1).to(device)\n",
    "\n",
    "    inputs = check_dim_and_resize(inputs)\n",
    "    h, w = inputs[0].shape[-2:]\n",
    "    scale = anchor_resolution / (h * w) * np.sqrt((vram_avail - anchor_memory_bias) / anchor_memory)\n",
    "    scale = 1 if scale > 1 else scale\n",
    "    scale = 1 / np.floor(1 / np.sqrt(scale) * 16) * 16\n",
    "    if scale < 1:\n",
    "        print(f\"显卡显存限制, 视频将会被缩小 {scale:.2f}倍\")\n",
    "    padding = int(16 / scale)\n",
    "    padder = InputPadder(inputs[0].shape, padding)\n",
    "    inputs = padder.pad(*inputs)\n",
    "\n",
    "    for i in range(iters):\n",
    "        print(f'Iter {i+1}. input_frames={len(inputs)} output_frames={2*len(inputs)-1}')\n",
    "        outputs = [inputs[0]]\n",
    "        for in_0, in_1 in zip(inputs[:-1], inputs[1:]):\n",
    "            in_0 = in_0.to(device)\n",
    "            in_1 = in_1.to(device)\n",
    "            with torch.no_grad():\n",
    "                imgt_pred = model(in_0, in_1, embt, scale_factor=scale, eval=True)['imgt_pred']\n",
    "            outputs += [imgt_pred.cpu(), in_1.cpu()]\n",
    "        inputs = outputs\n",
    "    outputs = padder.unpad(*outputs)\n",
    "\n",
    "    size = outputs[0].shape[2:][::-1]\n",
    "    writer = cv2.VideoWriter(f'{out_path}/demo.mp4', cv2.VideoWriter_fourcc(*'mp4v'), frame_ratio, size)\n",
    "    for i, imgt_pred in enumerate(outputs):\n",
    "        imgt_pred = tensor2img(imgt_pred)\n",
    "        imgt_pred = cv2.cvtColor(imgt_pred, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(imgt_pred)\n",
    "    writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5627c9-0e5c-4825-8fc4-3b8f0cf81c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1. input_frames=2 output_frames=3\n",
      "Iter 2. input_frames=3 output_frames=5\n",
      "Iter 3. input_frames=5 output_frames=9\n"
     ]
    }
   ],
   "source": [
    "interpoate(model, img0, img1, frame_ratio=24, iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f03e31-8312-45a0-962c-e27b70d443a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['epoch', 'state_dict'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c021f-b868-4eda-a209-05ca7e1fab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
